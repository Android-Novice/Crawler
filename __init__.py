from datetime import datetime
import baidu_crawler
import jianshu_orm
import jianshu_crawler
from jianshu_crawler import start_crawling

if __name__ == '__main__':
    # import re
    #
    # try:
    #     # Wide UCS-4 build
    #     myre = re.compile(u'['
    #                       u'\U0001F300-\U0001F64F'
    #                       u'\U0001F680-\U0001F6FF'
    #                       u'\u2600-\u2B55]+',
    #                       re.UNICODE)
    # except re.error:
    #     # Narrow UCS-2 build
    #     myre = re.compile(u'('
    #                       u'\ud83c[\udf00-\udfff]|'
    #                       u'\ud83d[\udc00-\ude4f\ude80-\udeff]|'
    #                       u'[\u2600-\u2B55])+',
    #                       re.UNICODE)
    # text = 'åˆšåˆšç©ç®€ä¹¦ï¼Œå‘ç°è¿™é‡Œæ˜¯æ–‡è‰ºé’å¹´çš„å¤©å ‚é˜¿â˜º æˆ‘æ˜¯ä¸€åæ‘„å½±å¸ˆï¼Œä¹Ÿå–œæ¬¢æ–‡å­—ï¼Œå¦‚æœå†™çš„æµ…æ˜¾ï¼Œæœ‰çš„æ—¶å€™ä¹Ÿä¼šè¯ç©·ï¼Œè°¢è°¢å¤§å®¶æŒ‡æ­£ï¼Œä¹Ÿå¯ä»¥å…³æ³¨æˆ‘çš„æ–°æµªå¾®åš@æ‘„å½±å¸ˆæ¨ä¹¦å¤ğŸ“·'
    # text1 = '4æœˆ14æ—¥Â·æ‰“å¡ğŸ”–èŠ·å¯¹ä½ è¯´'
    # text2 = 'ğŸ˜Šä¸åœ¨çš„æ—¶å€™å¯åŠ v15160324314'
    # text3 = 'å¤§å®¶æœ‰å–œæ¬¢èŒèŒå¤´åƒçš„å—ğŸ˜Šæƒ³è¦å±äºè‡ªå·±çš„æ‰£1æ— å¿åˆ¶ä½œ'
    # text4 = 'é—ªäº®æŠ¤çœ¼å°ç™¾ç§‘å…³äºè¿é£æµæ³ªçš„å°ç§‘æ™®1âƒ£ï¸äººä»¬é•¿æ—¶é—´æ‚£æ²™çœ¼ã€æ…¢æ€§ç»“è†œç‚æˆ–æ…¢æ€§é¼»ç‚ï¼Œå°±ä¼šç´¯åŠé¼»æ³ªç®¡ç²˜è†œï¼Œé€ æˆé¼»æ³ªç®¡é˜»å¡ã€‚ï¸æ³ªæ¶²ç§¯èšäºæ³ªå›Šä¸­ï¼Œçœ¼æ³ªå°±ä¼šä¸æ–­æµå‡ºã€‚ï¸å¦‚è¢«å†·é£ä¸€å¹ï¼Œæ³ªè…ºåˆ†æ³Œä¼šå¢å¤šï¼Œæ‰€ä»¥æµæ³ªä¹Ÿå°±ä¼šæ›´å¤šäº†ã€‚ï¸æ³ªä¸ºäººä½“äº”æ¶²ä¹‹ä¸€ï¼Œè‹¥ä¹…æµæ³ªä¸æ­¢ï¼Œéš¾è¾¨ç‰©è‰²ï¼Œç”šè‡³å¤±æ˜ã€‚ï¸å¯è§è¿é£æµæ³ªå¹¶éå°ç—…ï¼Œåº”åŠæ—©å°±æ²»ã€‚é—ªäº®æŠ¤çœ¼è´´ä¼šè®©ä½ æœ‰æ„æƒ³ä¸åˆ°çš„æ”¶è·, '
    # print(len(text4))
    # text = myre.sub('', text)
    # text1 = myre.sub('', text1)
    # text2 = myre.sub('', text2)
    # text3 = myre.sub('', text3)
    # text4 = myre.sub('', text4)
    # text4 = myre.sub('', text4)
    # text4 = myre.sub('', text4)
    # text4 = ''.join(text4[0:100])
    # print(text4)
    # print(111)

    start_crawling()

    # text = 'åˆšåˆšç©ç®€ä¹¦ï¼Œå‘ç°è¿™é‡Œæ˜¯æ–‡è‰ºé’å¹´çš„å¤©å ‚é˜¿â˜º æˆ‘æ˜¯ä¸€åæ‘„å½±å¸ˆï¼Œä¹Ÿå–œæ¬¢æ–‡å­—ï¼Œå¦‚æœå†™çš„æµ…æ˜¾ï¼Œæœ‰çš„æ—¶å€™ä¹Ÿä¼šè¯ç©·ï¼Œè°¢è°¢å¤§å®¶æŒ‡æ­£ï¼Œä¹Ÿå¯ä»¥å…³æ³¨æˆ‘çš„æ–°æµªå¾®åš@æ‘„å½±å¸ˆæ¨ä¹¦å¤ğŸ“·'
    # text = text.replace('ğŸ“·', '')

    # text = '4æœˆ14æ—¥Â·æ‰“å¡ğŸ”–èŠ·å¯¹ä½ è¯´'
    # text = text.replace('ğŸ“·', ' ')
    # text = text.replace('ğŸ”–',' ')
    # print('ğŸ“·'== 'ğŸ”–')
    # text = jianshu_crawler._replace_spacial_char(text)

    # jianshu_orm.init_mysql()
    # user = jianshu_orm.User()
    # user.id = '1'
    # user.like_count = 1
    # user.word_count = 10
    # user.article_count = 2
    # user.follower_count = 0
    # user.following_count = 1
    # user.name = 'test'
    # user.url = ''
    # user.image = 'about:blank'
    # user.articles = [
    #     jianshu_orm.Article('11', 'title', 'summary', '', datetime.now(), 100, 1000, 10000, 10, user.name),
    #     jianshu_orm.Article('211', '2title', '2summary', '', datetime.now(), 2100, 21000, 210000, 210, user.name)
    # ]
    # user.followers = [
    #     jianshu_orm.Follower('111111', 'follower', user.name),
    #     jianshu_orm.Follower('2111111', '2follower', user.name)
    # ]
    #
    # print('*********************************')
    # session = jianshu_orm.DBSession()
    # session.add(user)
    # session.commit()
    #
    # user.followers.append(jianshu_orm.Follower('31111111','Follower3', user.name))
    # user.articles.append(jianshu_orm.Article('311', '3title', '3summary', '', datetime.now(), 3100, 31000, 310000, 310, user.name))
    # session.add(user)
    # session.commit()

    # baidu_crawler.baiduWebCrawling('ç¾å¥³')
    pass
